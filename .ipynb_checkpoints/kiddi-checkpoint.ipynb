{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import calendar\n",
    "from datetime import date\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, roc_curve, auc, precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "class Kiddi():\n",
    "    def __init__(self, IS_RAW_PATH, IWP_PATH, IWES_PATH, CENSUS_PATH):\n",
    "        # self.df = pd.read_excel(IS_RAW_PATH)\n",
    "        # self.df_iwp = pd.read_excel(IWP_PATH)[['idd','peritonitisdate']]\n",
    "        # self.df_iwes = pd.read_excel(IWES_PATH)[['idd','exitsitedate']]\n",
    "        # self.df_census = pd.read_excel(CENSUS_PATH)[['idd','PatientAge','male','Diabetes','PDVintage','MQexist']]\n",
    "        self.df = colab_df\n",
    "        self.df_iwp = colab_df_iwp[['idd','peritonitisdate']]\n",
    "        self.df_iwes = colab_df_iwes[['idd','exitsitedate']]\n",
    "        self.df_census = colab_df_census[['idd','PatientAge','male','Diabetes','PDVintage','MQexist']]\n",
    "        self.target_df = None\n",
    "        self.population = None\n",
    "        self.is_raw_partition = dict()\n",
    "        self.st_data_dt = None\n",
    "        self.end_data_dt = None\n",
    "        self.is_raw_col = []\n",
    "        self.all_data = None\n",
    "        self.train = None\n",
    "        self.validation = None\n",
    "        self.test = None\n",
    "        self.train_X = None\n",
    "        self.train_y = None\n",
    "        self.val_X = None\n",
    "        self.val_y = None\n",
    "        self.test_X = None\n",
    "        self.test_y = None\n",
    "        self.model = None\n",
    "        self.final_score = None\n",
    "        self.prep_data = None\n",
    "        \n",
    "    def transform_is_raw(self):\n",
    "        recentLabCol = ['qRecentLabDt1','qRecentLabDt2','qRecentLabDt3','qRecentLabDt4']\n",
    "        # Change recent lab date to the end of month\n",
    "        df = self.get_df()\n",
    "        for index, col in enumerate(recentLabCol):\n",
    "          df['ft_data_dt_'+str(index)] = pd.to_datetime(df[col], format=\"%Y%m\")\n",
    "        feature_list = [\"qSodium1Val\", \"qSodium2Val\", \"qSodium3Val\", \"qSodium4Val\", \"qPotass1Val\", \"qPotass2Val\", \"qPotass3Val\", \n",
    "\"qPotass4Val\", \"qBicarb1Val\", \"qBicarb2Val\", \"qBicarb3Val\", \"qBicarb4Val\", \"qCreat1Val\", \"qCreat2Val\", \"qCreat3Val\", \n",
    "\"qCreat4Val\", \"qCaTotal1Val\", \"qCaTotal2Val\", \"qCaTotal3Val\", \"qCaTotal4Val\", \"qPhosph1Val\", \"qPhosph2Val\", \"qPhosph3Val\", \n",
    "\"qPhosph4Val\", \"qFGF231Val\", \"qFGF232Val\", \"qFGF233Val\", \"qFGF234Val\", \"qMagnesium1Val\", \"qMagnesium2Val\", \"qMagnesium3Val\", \n",
    "\"qMagnesium4Val\", \"qTotalProtein1Val\", \"qTotalProtein2Val\", \"qTotalProtein3Val\", \"qTotalProtein4Val\", \"qAlbumin1Val\", \"qAlbumin2Val\", \"qAlbumin3Val\", \n",
    "\"qAlbumin4Val\", \"qPTH1Val\", \"qPTH2Val\", \"qPTH3Val\", \"qPTH4Val\", \"qVitD25OH1Val\", \"qVitD25OH2Val\", \"qVitD25OH3Val\", \n",
    "\"qVitD25OH4Val\", \"qVitD125OH1Val\", \"qVitD125OH2Val\", \"qVitD125OH3Val\", \"qVitD125OH4Val\", \"qAlkPhosph1Val\", \"qAlkPhosph2Val\", \"qAlkPhosph3Val\", \n",
    "\"qAlkPhosph4Val\", \"qAlkPhosphBone1Val\", \"qAlkPhosphBone2Val\", \"qAlkPhosphBone3Val\", \"qAlkPhosphBone4Val\", \"qAST1Val\", \"qAST2Val\", \"qAST3Val\", \n",
    "\"qAST4Val\", \"qALT1Val\", \"qALT2Val\", \"qALT3Val\", \"qALT4Val\", \"qBilir1Val\", \"qBilir2Val\", \"qBilir3Val\", \n",
    "\"qBilir4Val\", \"qUricAcid1Val\", \"qUricAcid2Val\", \"qUricAcid3Val\", \"qUricAcid4Val\", \"qGlucose1Val\", \"qGlucose2Val\", \"qGlucose3Val\", \n",
    "\"qGlucose4Val\", \"qTotChol1Val\", \"qTotChol2Val\", \"qTotChol3Val\", \"qTotChol4Val\", \"qHDLChol1Val\", \"qHDLChol2Val\", \"qHDLChol3Val\", \n",
    "\"qHDLChol4Val\", \"qLDLChol1Val\", \"qLDLChol2Val\", \"qLDLChol3Val\", \"qLDLChol4Val\", \"qTriglyc1Val\", \"qTriglyc2Val\", \"qTriglyc3Val\", \n",
    "\"qTriglyc4Val\", \"qGlycoHgb1Val\", \"qGlycoHgb2Val\", \"qGlycoHgb3Val\", \"qGlycoHgb4Val\", \"qGlycoAlbumin1Val\", \"qGlycoAlbumin2Val\", \"qGlycoAlbumin3Val\", \n",
    "\"qGlycoAlbumin4Val\", \"qHgb1Val\", \"qHgb2Val\", \"qHgb3Val\", \"qHgb4Val\", \"qHct1Val\", \"qHct2Val\", \"qHct3Val\", \n",
    "\"qHct4Val\", \"qMCV1Val\", \"qMCV2Val\", \"qMCV3Val\", \"qMCV4Val\", \"qWhBldCnt1Val\", \"qWhBldCnt2Val\", \"qWhBldCnt3Val\", \n",
    "\"qWhBldCnt4Val\", \"qNeutrophils1Val\", \"qNeutrophils2Val\", \"qNeutrophils3Val\", \"qNeutrophils4Val\", \"qLymph1Val\", \"qLymph2Val\", \"qLymph3Val\", \n",
    "\"qLymph4Val\", \"qPlatelets1Val\", \"qPlatelets2Val\", \"qPlatelets3Val\", \"qPlatelets4Val\", \"qTSAT1Val\", \"qTSAT2Val\", \"qTSAT3Val\", \n",
    "\"qTSAT4Val\", \"qIron1Val\", \"qIron2Val\", \"qIron3Val\", \"qIron4Val\", \"qTIBC1Val\", \"qTIBC2Val\", \"qTIBC3Val\", \n",
    "\"qTIBC4Val\", \"qFerritin1Val\", \"qFerritin2Val\", \"qFerritin3Val\", \"qFerritin4Val\", \"qCHr1Val\", \"qCHr2Val\", \"qCHr3Val\", \n",
    "\"qCHr4Val\", \"qPctHypoRBC1Val\", \"qPctHypoRBC2Val\", \"qPctHypoRBC3Val\", \"qPctHypoRBC4Val\", \"qCReactProt1Val\", \"qCReactProt2Val\", \"qCReactProt3Val\", \n",
    "\"qCReactProt4Val\", \"qFibrinogen1Val\", \"qFibrinogen2Val\", \"qFibrinogen3Val\", \"qFibrinogen4Val\", \"qInterleukin1Val\", \"qInterleukin2Val\", \"qInterleukin3Val\", \n",
    "\"qInterleukin4Val\", \"qBeta2Microglob1Val\", \"qBeta2Microglob2Val\", \"qBeta2Microglob3Val\", \"qBeta2Microglob4Val\", \"qBNP1Val\", \"qBNP2Val\", \"qBNP3Val\", \n",
    "\"qBNP4Val\", \"qNTproBNP1Val\", \"qNTproBNP2Val\", \"qNTproBNP3Val\", \"qNTproBNP4Val\", \"qTropT1Val\", \"qTropT2Val\", \"qTropT3Val\", \n",
    "\"qTropT4Val\", \"qTropI1Val\", \"qTropI2Val\", \"qTropI3Val\", \"qTropI4Val\", \"qHepBAntigen1\", \"qHepBAntigen2\", \"qHepBAntigen3\", \n",
    "\"qHepBAntigen4\", \"qHepBSurfAntiBody1\", \"qHepBSurfAntiBody2\", \"qHepBSurfAntiBody3\", \"qHepBSurfAntiBody4\", \"qHepBSurfABLvl1\", \"qHepBSurfABUnit1\", \"qHepBSurfABLvl2\", \n",
    "\"qHepBSurfABUnit2\", \"qHepBSurfABLvl3\", \"qHepBSurfABUnit3\", \"qHepBSurfABLvl4\", \"qHepBSurfABUnit4\", \"qHepBCoreAntibody1\", \"qHepBCoreAntibody2\", \"qHepBCoreAntibody3\", \n",
    "\"qHepBCoreAntibody4\", \"qHepCAntiBody1\", \"qHepCAntiBody2\", \"qHepCAntiBody3\", \"qHepCAntiBody4\", \"qRecentLabVitalDt1\", \"qRecentLabVitalDt2\", \"qRecentLabVitalDt3\", \n",
    "\"qRecentLabVitalDt4\", \"qDiastolic1\", \"qSystolic1\", \"qDiastolic2\", \"qSystolic2\", \"qDiastolic3\", \"qSystolic3\", \"qDiastolic4\", \n",
    "\"qSystolic4\", \"qPulse1Val\", \"qPulse2Val\", \"qPulse3Val\", \"qPulse4Val\", \"qWeightVital1Val\", \"qWeightVital2Val\", \"qWeightVital3Val\", \n",
    "\"qWeightVital4Val\", \"qWeightVolVital1Val\", \"qWeightVolVital2Val\", \"qWeightVolVital3Val\", \"qWeightVolVital4Val\", \"qExchCAPD1\", \"qExchCAPD2\", \"qExchCAPD3\", \n",
    "\"qExchCAPD4\", \"qCAPDConnSys1\", \"qCAPDConnSysSpecify1\", \"qCAPDConnSys2\", \"qCAPDConnSysSpecify2\", \"qCAPDConnSys3\", \"qCAPDConnSysSpecify3\", \"qCAPDConnSys4\", \n",
    "\"qCAPDConnSysSpecify4\", \"qExchanges1\", \"qExchangesSpecify1\", \"qExchanges2\", \"qExchangesSpecify2\", \"qExchanges3\", \"qExchangesSpecify3\", \"qExchanges4\", \n",
    "\"qExchangesSpecify4\", \"qExch1CAPDDwellVol1\", \"qExch1CAPDDwellVol2\", \"qExch1CAPDDwellVol3\", \"qExch1CAPDDwellVol4\", \"qExch1CAPDBaxSolType1\", \"qExch1CAPDBaxSolType2\", \"qExch1CAPDBaxSolType3\", \n",
    "\"qExch1CAPDBaxSolType4\", \"qExch1CAPDBaxSolLoc\", \"qExch1CAPDOtherSolType1\", \"qExch1CAPDOtherSolType2\", \"qExch1CAPDOtherSolType3\", \"qExch1CAPDOtherSolType4\", \"qExch1CAPDOtherSolLoc\", \"qExch1CAPDDwellTime1\", \n",
    "\"qExch1CAPDDwellTime2\", \"qExch1CAPDDwellTime3\", \"qExch1CAPDDwellTime4\", \"qExch2CAPDDwellVol1\", \"qExch2CAPDDwellVol2\", \"qExch2CAPDDwellVol3\", \"qExch2CAPDDwellVol4\", \"qExch2CAPDBaxSolType1\", \n",
    "\"qExch2CAPDBaxSolType2\", \"qExch2CAPDBaxSolType3\", \"qExch2CAPDBaxSolType4\", \"qExch2CAPDBaxSolLoc\", \"qExch2CAPDOtherSolType1\", \"qExch2CAPDOtherSolType2\", \"qExch2CAPDOtherSolType3\", \"qExch2CAPDOtherSolType4\", \n",
    "\"qExch2CAPDOtherSolLoc\", \"qExch2CAPDDwellTime1\", \"qExch2CAPDDwellTime2\", \"qExch2CAPDDwellTime3\", \"qExch2CAPDDwellTime4\", \"qExch3CAPDDwellVol1\", \"qExch3CAPDDwellVol2\", \"qExch3CAPDDwellVol3\", \n",
    "\"qExch3CAPDDwellVol4\", \"qExch3CAPDBaxSolType1\", \"qExch3CAPDBaxSolType2\", \"qExch3CAPDBaxSolType3\", \"qExch3CAPDBaxSolType4\", \"qExch3CAPDBaxSolLoc\", \"qExch3CAPDOtherSolType1\", \"qExch3CAPDOtherSolType2\", \n",
    "\"qExch3CAPDOtherSolType3\", \"qExch3CAPDOtherSolType4\", \"qExch3CAPDOtherSolLoc\", \"qExch3CAPDDwellTime1\", \"qExch3CAPDDwellTime2\", \"qExch3CAPDDwellTime3\", \"qExch3CAPDDwellTime4\", \"qExch4CAPDDwellVol1\", \n",
    "\"qExch4CAPDDwellVol2\", \"qExch4CAPDDwellVol3\", \"qExch4CAPDDwellVol4\", \"qExch4CAPDBaxSolType1\", \"qExch4CAPDBaxSolType2\", \"qExch4CAPDBaxSolType3\", \"qExch4CAPDBaxSolType4\", \"qExch4CAPDBaxSolLoc\", \n",
    "\"qExch4CAPDOtherSolType1\", \"qExch4CAPDOtherSolType2\", \"qExch4CAPDOtherSolType3\", \"qExch4CAPDOtherSolType4\", \"qExch4CAPDOtherSolLoc\", \"qExch4CAPDDwellTime1\", \"qExch4CAPDDwellTime2\", \"qExch4CAPDDwellTime3\", \n",
    "\"qExch4CAPDDwellTime4\", \"qExchLCAPDDwellVol1\", \"qExchLCAPDDwellVol2\", \"qExchLCAPDDwellVol3\", \"qExchLCAPDDwellVol4\", \"qExchLCAPDBaxSolType1\", \"qExchLCAPDBaxSolType2\", \"qExchLCAPDBaxSolType3\", \n",
    "\"qExchLCAPDBaxSolType4\", \"qExchLCAPDBaxSolLoc\", \"qExchLCAPDOtherSolType1\", \"qExchLCAPDOtherSolType2\", \"qExchLCAPDOtherSolType3\", \"qExchLCAPDOtherSolType4\", \"qExchLCAPDOtherSolLoc\", \"qExchLCAPDDwellTime1\", \n",
    "\"qExchLCAPDDwellTime2\", \"qExchLCAPDDwellTime3\", \"qExchLCAPDDwellTime4\", \"qCAPDPrescrDays1\", \"qCAPDPrescrDays2\", \"qCAPDPrescrDays3\", \"qCAPDPrescrDays4\", \"qExchAPD1\", \n",
    "\"qExchAPD2\", \"qExchAPD3\", \"qExchAPD4\", \"qAPDCyclerMType1\", \"qAPDCyclerMTypeSpecify1\", \"qAPDCyclerMType2\", \"qAPDCyclerMTypeSpecify2\", \"qAPDCyclerMType3\", \n",
    "\"qAPDCyclerMTypeSpecify3\", \"qAPDCyclerMType4\", \"qAPDCyclerMTypeSpecify4\", \"qAPDCyclerCSys1\", \"qAPDCyclerCSys2\", \"qAPDCyclerCSys3\", \"qAPDCyclerCSys4\", \"qNumCycles1\", \n",
    "\"qNumCycles2\", \"qNumCycles3\", \"qNumCycles4\", \"qAPDTotCycleTime1\", \"qAPDTotCycleTime2\", \"qAPDTotCycleTime3\", \"qAPDTotCycleTime4\", \"qAPDDwellVol1\", \n",
    "\"qAPDDwellVol2\", \"qAPDDwellVol3\", \"qAPDDwellVol4\", \"qTotCyclerVol1\", \"qTotCyclerVol2\", \"qTotCyclerVol3\", \"qTotCyclerVol4\", \"qCyclerAPDBaxSolType1\", \n",
    "\"qCyclerAPDBaxSolType2\", \"qCyclerAPDBaxSolType3\", \"qCyclerAPDBaxSolType4\", \"qCyclerAPDOtherSolType1\", \"qCyclerAPDOtherSolType2\", \"qCyclerAPDOtherSolType3\", \"qCyclerAPDOtherSolType4\", \"qTidalAPD1\", \n",
    "\"qTidalAPD2\", \"qTidalAPD3\", \"qTidalAPD4\", \"qTidalAPDPct1\", \"qTidalAPDPct2\", \"qTidalAPDPct3\", \"qTidalAPDPct4\", \"qAPDNumDayExchange1\", \n",
    "\"qAPDNumDayExchange2\", \"qAPDNumDayExchange3\", \"qAPDNumDayExchange4\", \"qExch1APDCAPDDwellVol1\", \"qExch1APDCAPDDwellVol2\", \"qExch1APDCAPDDwellVol3\", \"qExch1APDCAPDDwellVol4\", \"qExch1APDCAPDBaxSolType1\", \n",
    "\"qExch1APDCAPDBaxSolType2\", \"qExch1APDCAPDBaxSolType3\", \"qExch1APDCAPDBaxSolType4\", \"qExch1APDCAPDBaxSolLoc\", \"qExch1APDCAPDOtherSolType1\", \"qExch1APDCAPDOtherSolType2\", \"qExch1APDCAPDOtherSolType3\", \"qExch1APDCAPDOtherSolType4\", \n",
    "\"qExch1APDCAPDOtherSolLoc\", \"qExch1APDCAPDDwellTime1\", \"qExch1APDCAPDDwellTime2\", \"qExch1APDCAPDDwellTime3\", \"qExch1APDCAPDDwellTime4\", \"qExch2APDCAPDDwellVol1\", \"qExch2APDCAPDDwellVol2\", \"qExch2APDCAPDDwellVol3\", \n",
    "\"qExch2APDCAPDDwellVol4\", \"qExch2APDCAPDBaxSolType1\", \"qExch2APDCAPDBaxSolType2\", \"qExch2APDCAPDBaxSolType3\", \"qExch2APDCAPDBaxSolType4\", \"qExch2APDCAPDBaxSolLoc\", \"qExch2APDCAPDOtherSolType1\", \"qExch2APDCAPDOtherSolType2\", \n",
    "\"qExch2APDCAPDOtherSolType3\", \"qExch2APDCAPDOtherSolType4\", \"qExch2APDCAPDOtherSolLoc\", \"qExch2APDCAPDDwellTime1\", \"qExch2APDCAPDDwellTime2\", \"qExch2APDCAPDDwellTime3\", \"qExch2APDCAPDDwellTime4\", \"qExch3APDCAPDDwellVol1\", \n",
    "\"qExch3APDCAPDDwellVol2\", \"qExch3APDCAPDDwellVol3\", \"qExch3APDCAPDDwellVol4\", \"qExch3APDCAPDBaxSolType1\", \"qExch3APDCAPDBaxSolType2\", \"qExch3APDCAPDBaxSolType3\", \"qExch3APDCAPDBaxSolType4\", \"qExch3APDCAPDBaxSolLoc\", \n",
    "\"qExch3APDCAPDOtherSolType1\", \"qExch3APDCAPDOtherSolType2\", \"qExch3APDCAPDOtherSolType3\", \"qExch3APDCAPDOtherSolType4\", \"qExch3APDCAPDOtherSolLoc\", \"qExch3APDCAPDDwellTime1\", \"qExch3APDCAPDDwellTime2\", \"qExch3APDCAPDDwellTime3\", \n",
    "\"qExch3APDCAPDDwellTime4\", \"qExch4APDCAPDDwellVol1\", \"qExch4APDCAPDDwellVol2\", \"qExch4APDCAPDDwellVol3\", \"qExch4APDCAPDDwellVol4\", \"qExch4APDCAPDBaxSolType1\", \"qExch4APDCAPDBaxSolType2\", \"qExch4APDCAPDBaxSolType3\", \n",
    "\"qExch4APDCAPDBaxSolType4\", \"qExch4APDCAPDBaxSolLoc\", \"qExch4APDCAPDOtherSolType1\", \"qExch4APDCAPDOtherSolType2\", \"qExch4APDCAPDOtherSolType3\", \"qExch4APDCAPDOtherSolType4\", \"qExch4APDCAPDOtherSolLoc\", \"qExch4APDCAPDDwellTime1\", \n",
    "\"qExch4APDCAPDDwellTime2\", \"qExch4APDCAPDDwellTime3\", \"qExch4APDCAPDDwellTime4\", \"qAPDCAPDPrescrDays1\", \"qAPDCAPDPrescrDays2\", \"qAPDCAPDPrescrDays3\", \"qAPDCAPDPrescrDays4\", \"qCGPDExchange\", \n",
    "\"qCGPrimeDesc\", \"qCGDescVisit\", \"qCGWeight\", \"qCGBP\", \"qCGSolStrength\", \"qCGCyclerSetup\", \"qCGCyclerConn\", \"qCGCyclerDisConn\", \n",
    "\"qCGExitSiteCare\", \"qCGCAPDExchange\", \"qPETestDt1\", \"qPETestDt2\", \"qPETestDt3\", \"qPETestDt4\", \"qPETestSol1\", \"qPETestSolSpecify1\", \n",
    "\"qPETestSol2\", \"qPETestSolSpecify2\", \"qPETestSol3\", \"qPETestSolSpecify3\", \"qPETestSol4\", \"qPETestSolSpecify4\", \"qCreatConVal1\", \"qCreatConUnit1\", \n",
    "\"qCreatConVal2\", \"qCreatConUnit2\", \"qCreatConVal3\", \"qCreatConUnit3\", \"qCreatConVal4\", \"qCreatConUnit4\", \"qCreatCon4HrVal1\", \"qCreatCon4HrUnit1\", \n",
    "\"qCreatCon4HrVal2\", \"qCreatCon4HrUnit2\", \"qCreatCon4HrVal3\", \"qCreatCon4HrUnit3\", \"qCreatCon4HrVal4\", \"qCreatCon4HrUnit4\", \"qCreatCon4HrCorVal1\", \"qCreatCon4HrCorUnit1\", \n",
    "\"qCreatCon4HrCorVal2\", \"qCreatCon4HrCorUnit2\", \"qCreatCon4HrCorVal3\", \"qCreatCon4HrCorUnit3\", \"qCreatCon4HrCorVal4\", \"qCreatCon4HrCorUnit4\", \"qDialysGlucConInitVal1\", \"qDialysGlucConInitUnit1\", \n",
    "\"qDialysGlucConInitVal2\", \"qDialysGlucConInitUnit2\", \"qDialysGlucConInitVal3\", \"qDialysGlucConInitUnit3\", \"qDialysGlucConInitVal4\", \"qDialysGlucConInitUnit4\", \"qDialysGlucCon4HrVal1\", \"qDialysGlucCon4HrUnit1\", \n",
    "\"qDialysGlucCon4HrVal2\", \"qDialysGlucCon4HrUnit2\", \"qDialysGlucCon4HrVal3\", \"qDialysGlucCon4HrUnit3\", \"qDialysGlucCon4HrVal4\", \"qDialysGlucCon4HrUnit4\", \"qDialysCreatRatio1\", \"qDialysCreatRatio2\", \n",
    "\"qDialysCreatRatio3\", \"qDialysCreatRatio4\", \"qPDDialysInstilled1\", \"qPDDialysInstilled2\", \"qPDDialysInstilled3\", \"qPDDialysInstilled4\", \"qPDDialysDrained1\", \"qPDDialysDrained2\", \n",
    "\"qPDDialysDrained3\", \"qPDDialysDrained4\", \"qPDSol227Use\", \"qPDSol386Use\", \"qRecentLabRKFDt1\", \"qRecentLabRKFDt2\", \"qRecentLabRKFDt3\", \"qRecentLabRKFDt4\", \n",
    "\"qUrine24HrVol1Val\", \"qUrine24HrVol2Val\", \"qUrine24HrVol3Val\", \"qUrine24HrVol4Val\", \"qUrine24HrCreat1Val\", \"qUrine24HrCreat2Val\", \"qUrine24HrCreat3Val\", \"qUrine24HrCreat4Val\", \n",
    "\"qUrine24HrUrea1Val\", \"qUrine24HrUrea2Val\", \"qUrine24HrUrea3Val\", \"qUrine24HrUrea4Val\", \"qSerumUrea1Val\", \"qSerumUrea2Val\", \"qSerumUrea3Val\", \"qSerumUrea4Val\", \n",
    "\"qSerumCreat1Val\", \"qSerumCreat2Val\", \"qSerumCreat3Val\", \"qSerumCreat4Val\", \"qResidKtVUrea1Val\", \"qResidKtVUrea2Val\", \"qResidKtVUrea3Val\", \"qResidKtVUrea4Val\", \n",
    "\"qPeritonealKtVUrea1Val\", \"qPeritonealKtVUrea2Val\", \"qPeritonealKtVUrea3Val\", \"qPeritonealKtVUrea4Val\", \"qTotKtVUrea1Val\", \"qTotKtVUrea2Val\", \"qTotKtVUrea3Val\", \"qTotKtVUrea4Val\", \n",
    "\"qTot24HrPDFluidIn1Val\", \"qTot24HrPDFluidIn2Val\", \"qTot24HrPDFluidIn3Val\", \"qTot24HrPDFluidIn4Val\", \"qTot24HrPDFluidOut1Val\", \"qTot24HrPDFluidOut2Val\", \"qTot24HrPDFluidOut3Val\", \"qTot24HrPDFluidOut4Val\", \n",
    "\"qTot24HrDialyUrea1Val\", \"qTot24HrDialyUrea2Val\", \"qTot24HrDialyUrea3Val\", \"qTot24HrDialyUrea4Val\", \"qCreatClearance1Val\", \"qCreatClearance2Val\", \"qCreatClearance3Val\", \"qCreatClearance4Val\", \n",
    "\"qWeight1Val\", \"qWeight2Val\", \"qWeight3Val\", \"qWeight4Val\", \"qWeightVol1Val\", \"qWeightVol2Val\", \"qWeightVol3Val\", \"qWeightVol4Val\", \n",
    "\"qSolESC_OSTXT\", \"qESPStrategy_OSTXT\", \"qESPOtherOintment\", \"qPTBloodTransYN4\", \"qPTBloodTransUnit1\", \"qPTBloodTransYN3\", \"qPTBloodTransUnit2\", \"qPTBloodTransYN2\", \n",
    "\"qPTBloodTransUnit3\", \"qPTBloodTransYN1\", \"qPTBloodTransUnit4\", \"qIndicateLoc1\", \"qIndicateLoc2\", \"qIndicateLoc3\", \"qIndicateLoc4\", \"qOralNutr\", \n",
    "\"qAminoAcidSuppl\", \"qVitaminPrep\", \"qFacilityPDVisit1\", \"qFacilityPDVisit2\", \"qFacilityPDVisit3\", \"qFacilityPDVisit4\", \"qHomePDVisit1\", \"qHomePDVisit2\", \n",
    "\"qHomePDVisit3\", \"qHomePDVisit4\", \"qHomePDVisitCnt1\", \"qHomePDVisitCnt2\", \"qHomePDVisitCnt3\", \"qHomePDVisitCnt4\", \"BactInfec1\", \"BactInfec2\", \n",
    "\"BactInfec3\", \"BactInfec4\", \"DialAccessRelInfec1\", \"DialAccessRelInfec2\", \"DialAccessRelInfec3\", \"DialAccessRelInfec4\", ]\n",
    "        rm_key_ft_data_dt = [\"idd\", \"ft_data_dt_0\", \"ft_data_dt_1\", \"ft_data_dt_2\", \"ft_data_dt_3\"]\n",
    "        df = df[rm_key_ft_data_dt + feature_list]\n",
    "        # rename column\n",
    "        col1 = [c for c in feature_list if c[-1] == '1' or '1Val' in c]\n",
    "        col2 = [c for c in feature_list if c[-1] == '2' or '2Val' in c]\n",
    "        col3 = [c for c in feature_list if c[-1] == '3' or '3Val' in c]\n",
    "        col4 = [c for c in feature_list if c[-1] == '4' or '4Val' in c]\n",
    "        col_rename_1 = [(c, c[:-1]) if c[-1] == '1' else (c, c.replace(\"1Val\", \"Val\")) for c in col1]\n",
    "        col_rename_2 = [(c, c[:-1]) if c[-1] == '2' else (c, c.replace(\"2Val\", \"Val\")) for c in col2]\n",
    "        col_rename_3 = [(c, c[:-1]) if c[-1] == '3' else (c, c.replace(\"3Val\", \"Val\")) for c in col3]\n",
    "        col_rename_4 = [(c, c[:-1]) if c[-1] == '4' else (c, c.replace(\"4Val\", \"Val\")) for c in col4]\n",
    "        df1 = df[['idd', 'ft_data_dt_0'] + col1].rename(columns = dict(col_rename_1))\n",
    "        df2 = df[['idd', 'ft_data_dt_1'] + col2].rename(columns = dict(col_rename_2))\n",
    "        df3 = df[['idd', 'ft_data_dt_2'] + col3].rename(columns = dict(col_rename_3))\n",
    "        df4 = df[['idd', 'ft_data_dt_3'] + col4].rename(columns = dict(col_rename_4))\n",
    "        df1 = df1.rename(columns = {'ft_data_dt_0' : 'ft_data_dt'})\n",
    "        df2 = df2.rename(columns = {'ft_data_dt_1' : 'ft_data_dt'})\n",
    "        df3 = df3.rename(columns = {'ft_data_dt_2' : 'ft_data_dt'})\n",
    "        df4 = df4.rename(columns = {'ft_data_dt_3' : 'ft_data_dt'})\n",
    "        df_new = pd.concat([df1, df2, df3, df4]).sort_values(by=['ft_data_dt', 'idd']).reset_index(drop=True) \n",
    "        df_new['ft_data_dt'] = pd.to_datetime(df_new['ft_data_dt'], format=\"%Y%m\") + MonthEnd(1)\n",
    "        df_new = df_new.dropna(subset=['ft_data_dt'])\n",
    "        df_new = df_new.dropna(axis = 1, how='all')\n",
    "        self.set_is_raw_col([c for c in df_new.columns if c not in ['idd', 'ft_data_dt']])\n",
    "        self.set_df(df_new)\n",
    "        \n",
    "    def transform_census(self):\n",
    "        df_census = self.get_df_census()\n",
    "        impute = {'Yes':1, 'No':0, np.nan:np.nan}\n",
    "        df_census['male'] = df_census['male'].apply(lambda x : impute[x])\n",
    "        df_census['Diabetes'] = df_census['Diabetes'].apply(lambda x : impute[x])\n",
    "        self.set_df_census(df_census)\n",
    "        \n",
    "    def clean_data(self):\n",
    "        self.transform_is_raw()\n",
    "        self.transform_census()\n",
    "        \n",
    "    def gen_target(self):\n",
    "        df_iwp = self.get_df_iwp()\n",
    "        df_iwes = self.get_df_iwes()\n",
    "        df_iwes = df_iwes.rename(columns={'exitsitedate':'ft_data_dt'})\n",
    "        df_iwp = df_iwp.rename(columns={'peritonitisdate':'ft_data_dt'})\n",
    "        df_infect = df_iwes.merge(df_iwp, how='outer')\n",
    "        df_infect = df_infect.dropna(axis=0)\n",
    "        first_infect = df_infect.groupby(['idd']).min()\n",
    "        first_infect = first_infect.reset_index()\n",
    "        first_infect['target'] = 1\n",
    "        first_infect['ft_data_dt'] = pd.to_datetime(first_infect['ft_data_dt'], format=\"%Y%m\") + MonthEnd(1)\n",
    "        all_target = []\n",
    "        end_data_dt = self.get_end_data_dt()\n",
    "        print(end_data_dt)\n",
    "        for index, row in first_infect.iterrows():\n",
    "            date_series = pd.date_range(*(pd.to_datetime([row['ft_data_dt'], end_data_dt]) + pd.offsets.MonthEnd()), freq='M', name='ft_data_dt')\n",
    "            idd_list = [row['idd']]\n",
    "            idd_series = pd.Series(data=idd_list, name='idd')\n",
    "            date_frame = date_series.to_frame()\n",
    "            idd_frame = idd_series.to_frame()\n",
    "            date_frame['key'] = 0\n",
    "            idd_frame['key'] = 0\n",
    "            tmp_target = idd_frame.merge(date_frame, on='key', how='outer').drop(columns=['key'])\n",
    "            all_target.append(tmp_target)\n",
    "        target = pd.concat(all_target)\n",
    "        target['target'] = 1\n",
    "        self.set_target_df(target)\n",
    "        \n",
    "    def gen_population(self):\n",
    "        df = self.get_df()\n",
    "        idd_list = list(set(df['idd'].to_list()))\n",
    "        date_list = df['ft_data_dt'].to_list()\n",
    "        st_data_dt = min(date_list)\n",
    "        end_data_dt = max(date_list)\n",
    "        self.set_st_data_dt(st_data_dt)\n",
    "        self.set_end_data_dt(end_data_dt)\n",
    "        date_series = pd.date_range(*(pd.to_datetime([st_data_dt, end_data_dt]) + pd.offsets.MonthEnd()), freq='M', name='ft_data_dt')\n",
    "        date_frame = date_series.to_frame()\n",
    "        idd_series = pd.Series(data=idd_list, name='idd')\n",
    "        idd_frame = idd_series.to_frame()\n",
    "        date_frame['key'] = 0\n",
    "        idd_frame['key'] = 0\n",
    "        population = idd_frame.merge(date_frame, on='key', how='outer').drop(columns=['key'])\n",
    "        self.set_population(population)\n",
    "    \n",
    "    def partition_is_raw(self):\n",
    "        is_raw_partition = self.get_is_raw_partition()\n",
    "        df = self.get_df()\n",
    "#         df['ft_data_dt'] = pd.to_datetime(df['ft_data_dt'], format=\"%Y%m\") + MonthEnd(1)\n",
    "        st_data_dt = self.get_st_data_dt()\n",
    "        end_data_dt = self.get_end_data_dt()\n",
    "        date_series = pd.date_range(*(pd.to_datetime([st_data_dt, end_data_dt]) + pd.offsets.MonthEnd()), freq='M', name='ft_data_dt')\n",
    "        date_series = date_series.to_list()\n",
    "        for d in date_series:\n",
    "            is_raw_partition[d.strftime(\"%Y-%m-%d\")] = df[df['ft_data_dt'] == d]\n",
    "        self.set_is_raw_partition(is_raw_partition)\n",
    "        self.set_df(df)\n",
    "        \n",
    "    def feature_engineer_ts(self, month=12):\n",
    "        \"\"\"\n",
    "        Time series features\n",
    "        \"\"\"\n",
    "        st_data_dt = self.get_st_data_dt()\n",
    "        end_data_dt = self.get_end_data_dt()\n",
    "        date_list = pd.date_range(*(pd.to_datetime([st_data_dt, end_data_dt]) + pd.offsets.MonthEnd()), freq='M').to_list()\n",
    "        population = self.get_population()\n",
    "        is_raw_partition = self.get_is_raw_partition()\n",
    "#         Lag 2 months\n",
    "        # population['ft_data_dt'] = population['ft_data_dt'].astype('datetime64[M]') - pd.DateOffset(months=2) + MonthEnd(1)\n",
    "        all_data = []\n",
    "#         join past is_raw columns\n",
    "        for d in date_list:\n",
    "            \n",
    "            population_partition = population[population['ft_data_dt'] == d] \n",
    "            old_date = d - relativedelta(months=month)\n",
    "            y = old_date.year\n",
    "            m = old_date.month\n",
    "            day = calendar.monthrange(y, m)[1]\n",
    "            old_date = date(y, m, day)\n",
    "            old_date = max(old_date, st_data_dt)\n",
    "            date_list_join = pd.date_range(*(pd.to_datetime([old_date, d]) + pd.offsets.MonthEnd()), freq='M').to_list()\n",
    "            date_list_join.reverse()\n",
    "            for index, date_join in enumerate(date_list_join):\n",
    "                if date_join.strftime(\"%Y-%m-%d\") not in is_raw_partition.keys():\n",
    "                    continue\n",
    "                \n",
    "                tmp_is_raw_partition = is_raw_partition[date_join.strftime(\"%Y-%m-%d\")]\n",
    "                \n",
    "                rename_col = [c for c in list(tmp_is_raw_partition.columns) if c not in ['idd', 'ft_data_dt']]\n",
    "                new_col = [c+'_'+str(index+1) for c in rename_col]\n",
    "                name_dict = dict(list(zip(rename_col, new_col)))\n",
    "                tmp_is_raw_partition = tmp_is_raw_partition.rename(columns = name_dict)\n",
    "                population_partition = population_partition.merge(tmp_is_raw_partition.drop(columns=['ft_data_dt']), on=['idd'], how='left')\n",
    "            all_data.append(population_partition)\n",
    "        ts_df = pd.concat(all_data)\n",
    "        threshold_null = len(ts_df.columns) - 4\n",
    "        ts_df = ts_df[ts_df.isnull().sum(axis=1) < threshold_null]\n",
    "        \n",
    "        def sum_ts(self, df, col_list, feature, duration):\n",
    "            ft_name = feature+ '_sum_'+str(duration)+'mth'\n",
    "            tmp_df = df[col_list].sum(axis = 1).to_frame(name=ft_name)\n",
    "            return tmp_df\n",
    "    \n",
    "        def mean_ts(self, df, col_list, feature, duration):\n",
    "            ft_name = feature+ '_avg_'+str(duration)+'mth'\n",
    "            tmp_df = df[col_list].mean(axis = 1).to_frame(name=ft_name)\n",
    "            return tmp_df\n",
    "        \n",
    "        def std_ts(self, df, col_list, feature, duration):\n",
    "            ft_name = feature+ '_std_'+str(duration)+'mth'\n",
    "            tmp_df = df[col_list].std(axis = 1).to_frame(name=ft_name)\n",
    "            return tmp_df\n",
    "        \n",
    "        def med_ts(self, df, col_list, feature, duration):\n",
    "            ft_name = feature+ '_med_'+str(duration)+'mth'\n",
    "            tmp_df = df[col_list].std(axis = 1).to_frame(name=ft_name)\n",
    "            return tmp_df\n",
    "        \n",
    "        def min_ts(self, df, col_list, feature, duration):\n",
    "            ft_name = feature+ '_min_'+str(duration)+'mth'\n",
    "            tmp_df = df[col_list].min(axis = 1).to_frame(name=ft_name)\n",
    "            return tmp_df\n",
    "        \n",
    "        def max_ts(self, df, col_list, feature, duration):\n",
    "            ft_name = feature+ '_max_'+str(duration)+'mth'\n",
    "            tmp_df = df[col_list].max(axis = 1).to_frame(name=ft_name)\n",
    "            return tmp_df\n",
    "        \n",
    "        def q1_ts(self, df, col_list, feature, duration):\n",
    "            ft_name = feature+ '_q1_'+str(duration)+'mth'\n",
    "            tmp_df = df[col_list].quantile(q=0.25, axis = 1).to_frame(name=ft_name)\n",
    "            return tmp_df\n",
    "        \n",
    "        def q3_ts(self, df, col_list, feature, duration):\n",
    "            ft_name = feature+ '_q3_'+str(duration)+'mth'\n",
    "            tmp_df = df[col_list].quantile(q=0.75, axis = 1).to_frame(name=ft_name)\n",
    "            return tmp_df\n",
    "        \n",
    "        # def rank_ts(self, df, col_list, feature, duration):\n",
    "        #     ft_name = feature+ '_rank_'+str(duration)+'mth'\n",
    "        #     tmp_df = df[col_list].rank(axis = 0)\n",
    "        #     return tmp_df\n",
    "        \n",
    "        def last_ts(self, df, feature):\n",
    "            ft_name = feature+ '_last'\n",
    "            tmp_df = df[feature+'_'+str(1)].to_frame(name=ft_name)\n",
    "            return tmp_df\n",
    "        \n",
    "        ts_duration = [1, 3, 6, 9, 12]\n",
    "        feature_list = self.get_is_raw_col()\n",
    "        df = ts_df[['idd', 'ft_data_dt']]\n",
    "#         Time Series Features\n",
    "        for duration in ts_duration:\n",
    "            for col in feature_list:\n",
    "                col_list = [col+'_'+str(i) for i in range(1, duration+1)]\n",
    "                df = pd.concat([df\\\n",
    "                                , sum_ts(self, ts_df, col_list, col, duration)\\\n",
    "                                , mean_ts(self, ts_df, col_list, col, duration)\\\n",
    "                                , med_ts(self, ts_df, col_list, col, duration)\\\n",
    "                                , q1_ts(self, ts_df, col_list, col, duration)\\\n",
    "                                , q3_ts(self, ts_df, col_list, col, duration)\\\n",
    "                                , min_ts(self, ts_df, col_list, col, duration)\\\n",
    "                                , max_ts(self, ts_df, col_list, col, duration)]\n",
    "                                # , rank_ts(self, ts_df, col_list, col, duration)\\\n",
    "                                # , last_ts(self, ts_df, col)]\n",
    "                                , axis=1)\n",
    "        self.set_all_data(df)\n",
    "        \n",
    "\n",
    "    def feature_engineer_segment(self):\n",
    "        df = self.get_all_data()\n",
    "        # df = global_df\n",
    "        # join with census\n",
    "        census_df = self.get_df_census()\n",
    "\n",
    "        # drop row that has null more than 20%\n",
    "        thresh = len(df) * .8\n",
    "        df = df.dropna(thresh = thresh, axis = 1)\n",
    "        \n",
    "        # select only numeric col\n",
    "        c_list = [c for c in list(df.columns) if c not in ['idd', 'ft_data_dt', 'target']]\n",
    "        for col in c_list:\n",
    "            if not is_numeric_dtype(df[col]):\n",
    "                df = df.drop(columns=[col])\n",
    "        \n",
    "        to_calculate_col = [c for c in list(df.columns) if c not in ['idd', 'ft_data_dt', 'target']]\n",
    "        df = df.merge(census_df, on=['idd'], how='left')\n",
    "        #  join with lag target\n",
    "        target_df = self.get_target_df()\n",
    "        target_df = target_df.rename({'target' : 'lag_target'})\n",
    "        df = df.merge(target_df, on = ['idd', 'ft_data_dt'], how='left')\n",
    "\n",
    "        # def zscore_segment(self, df, feature, segment):\n",
    "        #     ft_name = 'zscore_' + segment + '_' + feature\n",
    "\n",
    "        #     if df[feature].count(0) == len(df[feature]):\n",
    "        #         zscore = df[feature]\n",
    "        #     else:\n",
    "        #         zscore = stats.zscore(df[feature], nan_policy = 'omit')\n",
    "        #     zscore = pd.Series(zscore, name = ft_name)\n",
    "        #     return zscore.to_frame(name=ft_name)\n",
    "        \n",
    "#         calculate Age range\n",
    "        age1 = df[((df['PatientAge'] > 0) & (df['PatientAge'] <= 10))]\n",
    "        age2 = df[((df['PatientAge'] > 10) & (df['PatientAge'] <= 20))]\n",
    "        age3 = df[((df['PatientAge'] > 20) & (df['PatientAge'] <= 30))]\n",
    "        age4 = df[((df['PatientAge'] > 30) & (df['PatientAge'] <= 40))]\n",
    "        age5 = df[((df['PatientAge'] > 40) & (df['PatientAge'] <= 50))]\n",
    "        age6 = df[((df['PatientAge'] > 50) & (df['PatientAge'] <= 60))]\n",
    "        age7 = df[((df['PatientAge'] > 60) & (df['PatientAge'] <= 70))]\n",
    "        age8 = df[((df['PatientAge'] > 70) & (df['PatientAge'] <= 80))]\n",
    "        age9 = df[((df['PatientAge'] > 80) & (df['PatientAge'] <= 90))]\n",
    "        age10 = df[(df['PatientAge'] > 90)]\n",
    "        age_df = [age1, age2, age3, age4, age5, age6, age7, age8, age9, age10]\n",
    "        print('age')\n",
    "        for index, age in enumerate(age_df):\n",
    "            # print(index)\n",
    "            use_col = []\n",
    "            for feature in to_calculate_col:\n",
    "                if age[feature].std(ddof=0) == 0:\n",
    "                    continue\n",
    "                # df['zscore_age_' + feature] = (age[feature] - age[feature].mean())/age[feature].std(ddof=0)\n",
    "                use_col.append('zscore_age_' + feature)\n",
    "                age['zscore_age_' + feature] = (age[feature] - age[feature].mean())/age[feature].std(ddof=0)\n",
    "            age = age[['idd', 'ft_data_dt'] + use_col]\n",
    "            df = df.merge(age, on=['idd','ft_data_dt'], how='left')\n",
    "\n",
    "        male = df[df['male'] == 1]\n",
    "        female = df[df['male'] == 0]\n",
    "        print('sex')\n",
    "        sex = [male, female]\n",
    "        for sexual in sex:\n",
    "            use_col = []\n",
    "            for feature in to_calculate_col:\n",
    "                if sexual[feature].std(ddof=0) == 0:\n",
    "                    continue\n",
    "                # df['zscore_sex_' + feature] = (sexual[feature] - sexual[feature].mean())/sexual[feature].std(ddof=0)\n",
    "                use_col.append('zscore_sex_' + feature)\n",
    "                sexual['zscore_sex_' + feature] = (sexual[feature] - sexual[feature].mean())/sexual[feature].std(ddof=0)\n",
    "            sexual = sexual[['idd', 'ft_data_dt'] + use_col]\n",
    "            df = df.merge(sexual, on=['idd', 'ft_data_dt'], how='left')\n",
    "        print('diabete')\n",
    "        isDiabete = df[df['Diabetes'] == 1]\n",
    "        isNotDiabete = df[df['Diabetes'] == 0]\n",
    "\n",
    "        dia = [isDiabete, isNotDiabete]\n",
    "        for d in dia:\n",
    "            use_col = []\n",
    "            for feature in to_calculate_col:\n",
    "                if d[feature].std(ddof=0) == 0:\n",
    "                    continue\n",
    "                # df['zscore_dia_' + feature] = (d[feature] - d[feature].mean())/d[feature].std(ddof=0)\n",
    "                use_col.append('zscore_dia_' + feature)\n",
    "                d['zscore_dia_' + feature] = (d[feature] - d[feature].mean())/d[feature].std(ddof=0)\n",
    "            d = d[['idd', 'ft_data_dt'] + use_col]\n",
    "            df = df.merge(d, on=['idd', 'ft_data_dt'], how='left')\n",
    "            \n",
    "        self.set_all_data(df)\n",
    "    \n",
    "    def join_target(self):\n",
    "        df = self.get_all_data()\n",
    "        thresh = len(df) * .7\n",
    "        df = df.dropna(thresh = thresh, axis = 1)\n",
    "        target_df = self.get_target_df()\n",
    "        target_df['ft_data_dt'] = target_df['ft_data_dt'].astype('datetime64[M]') - pd.DateOffset(months=2) + MonthEnd(1)\n",
    "        df = df.merge(target_df, on=['idd', 'ft_data_dt'], how='left')\n",
    "        values = {'target': 0}\n",
    "        # df.fillna(value=values, inplace=True)\n",
    "        # df = df.fillna(0, subset=['target'])\n",
    "        df['target'] = df['target'].replace(np.nan, 0)\n",
    "        self.set_prep_data(df)\n",
    "\n",
    "    def prep_data_fn(self, st_train_dt, end_train_dt, st_val_dt, end_val_dt, st_test_dt, end_test_dt):\n",
    "        df = self.get_prep_data()\n",
    "        train = df[(df['ft_data_dt'] >= st_train_dt) & (df['ft_data_dt'] <= end_train_dt)]\n",
    "        val = df[(df['ft_data_dt'] >= st_val_dt) & (df['ft_data_dt'] <= end_val_dt)].sample(frac=0.4, random_state=2021)\n",
    "        test = df[(df['ft_data_dt'] >= st_test_dt) & (df['ft_data_dt'] <= end_test_dt)]\n",
    "        print(f'----train----')\n",
    "        print(train['ft_data_dt', 'target', 'idd'].groupby(['ft_data_dt', 'target']).agg(['count']))\n",
    "        print(f'----validation----')\n",
    "        print(val['ft_data_dt', 'target', 'idd'].groupby(['ft_data_dt', 'target']).agg(['count']))\n",
    "        print(f'----test----')\n",
    "        print(test['ft_data_dt', 'target', 'idd'].groupby(['ft_data_dt', 'target']).agg(['count']))\n",
    "        self.set_train(train)\n",
    "        self.set_validation(val)\n",
    "        self.set_test(test)\n",
    "        train_X = train[[c for c in train.columns if c not in ['idd', 'ft_data_dt', 'target']]]\n",
    "        train_y = train['target']\n",
    "        val_X = val[[c for c in train.columns if c not in ['idd', 'ft_data_dt', 'target']]]\n",
    "        val_y = val['target']\n",
    "        test_X = test[[c for c in train.columns if c not in ['idd', 'ft_data_dt', 'target']]]\n",
    "        test_y = test['target']\n",
    "        self.set_train_X(train_X)\n",
    "        self.set_train_y(train_y)\n",
    "        self.set_val_X(val_X)\n",
    "        self.set_val_y(val_y)\n",
    "        self.set_test_X(test_X)\n",
    "        self.set_test_y(test_y)\n",
    "\n",
    "    def train_model(self, model, hyperparameter_dict):\n",
    "        if model == 'random_forest':\n",
    "            clf = RandomForestClassifier(max_depth=hyperparameter_dict['depth'], n_estimators = hyperparameter_dict['tree_num'], random_state = 2021)\n",
    "        elif model == 'XGBoost':\n",
    "            clf = XGBClassifier(objective='binary:logistic', random_state=2021, max_depth = hyperparameter_dict['depth'], n_estimators = hyperparameter_dict['tree_num'])\n",
    "        elif model == 'gbt':\n",
    "            clf = GradientBoostingClassifier(n_estimators = hyperparameter_dict['tree_num'], max_depth = hyperparameter_dict['depth'], random_state = 2021)\n",
    "        else:\n",
    "            print(f'please enter model among [\"random_forest\", \"XGBoost\", \"gbt\"]')\n",
    "            # return\n",
    "        X_train = self.get_train_X()\n",
    "        y_train = self.get_train_y()\n",
    "        X_val = self.get_val_X()\n",
    "        y_val = self.get_val_y()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_result = clf.predict_proba(X_train)\n",
    "        now_depth = hyperparameter_dict['depth']\n",
    "        now_tree_num = hyperparameter_dict['tree_num']\n",
    "        print(f'depth is : {now_depth}, tree_num : {now_tree_num}')\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_train, train_result)\n",
    "        print(f'train auc : {metrics.auc(fpr, tpr)}')\n",
    "        val_result = clf.predict_proba(X_val)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_train, val_result)\n",
    "        print(f'validation auc : {metrics.auc(fpr, tpr)}')\n",
    "        self.set_model(clf)\n",
    "        return clf\n",
    "\n",
    "    def get_prob(self):\n",
    "        X_test = self.get_test_X()\n",
    "        y_test = self.get_test_y()\n",
    "        clf = self.get_model()\n",
    "        test_result = clf.predict_proba(X_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_train, test_result)\n",
    "        print(f'test auc : {metrics.auc(fpr, tpr)}')\n",
    "        score_list = pd.Series(test_result, name='score').to_frame()\n",
    "        test = self.get_test()[['idd', 'ft_data_dt']]\n",
    "        test = pd.concat([test, score_list], axis = 1)\n",
    "        self.set_final_score(test)\n",
    "        return test\n",
    "\n",
    "    def roc_graph(self):\n",
    "        y_true = self.get_test_y()\n",
    "        X_test = self.get_test_X()\n",
    "        clf = self.get_model()\n",
    "        test_result = clf.predict_proba(X_test)\n",
    "        skplt.metrics.plot_roc_curve(y_true, test_result)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "    \n",
    "    def set_df(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def get_df_iwp(self):\n",
    "        return self.df_iwp\n",
    "    \n",
    "    def set_df_iwp(self, df_iwp):\n",
    "        self.df_iwp = df_iwp\n",
    "        \n",
    "    def get_df_iwes(self):\n",
    "        return self.df_iwes\n",
    "    \n",
    "    def set_df_iwes(self, df_iwes):\n",
    "        self.df_iwes = df_iwes\n",
    "        \n",
    "    def get_df_census(self):\n",
    "        return self.df_census\n",
    "    \n",
    "    def set_df_census(self, df_census):\n",
    "        self.df_census = df_census\n",
    "    \n",
    "    def get_target_df(self):\n",
    "        return self.target_df\n",
    "    \n",
    "    def set_target_df(self, target_df):\n",
    "        self.target_df = target_df\n",
    "        \n",
    "    def get_population(self):\n",
    "        return self.population\n",
    "    \n",
    "    def set_population(self, population):\n",
    "        self.population = population\n",
    "        \n",
    "    def get_st_data_dt(self):\n",
    "        return self.st_data_dt\n",
    "    \n",
    "    def set_st_data_dt(self, st_data_dt):\n",
    "        self.st_data_dt = st_data_dt\n",
    "        \n",
    "    def get_end_data_dt(self):\n",
    "        return self.end_data_dt\n",
    "    \n",
    "    def set_end_data_dt(self, end_data_dt):\n",
    "        self.end_data_dt = end_data_dt\n",
    "    \n",
    "    def get_is_raw_partition(self):\n",
    "        return self.is_raw_partition\n",
    "    \n",
    "    def set_is_raw_partition(self, is_raw_partition):\n",
    "        self.is_raw_partition = is_raw_partition\n",
    "        \n",
    "    def get_is_raw_col(self):\n",
    "        return self.is_raw_col\n",
    "    \n",
    "    def set_is_raw_col(self, is_raw_col):\n",
    "        self.is_raw_col = is_raw_col\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.all_data\n",
    "    \n",
    "    def set_all_data(self, all_data):\n",
    "        self.all_data = all_data\n",
    "\n",
    "    def get_train(self):\n",
    "        return self.train\n",
    "\n",
    "    def set_train(self, train):\n",
    "        self.train = train\n",
    "\n",
    "    def get_validation(self):\n",
    "        return self.validation\n",
    "    \n",
    "    def set_validation(self, validation):\n",
    "        self.validation = validation\n",
    "\n",
    "    def get_test(self):\n",
    "        return self.test\n",
    "      \n",
    "    def set_test(self, test):\n",
    "        self.test = test\n",
    "\n",
    "    def get_train_X(self):\n",
    "        return self.train_X\n",
    "    \n",
    "    def set_train_X(self, train_X):\n",
    "        self.train_X = train_X\n",
    "\n",
    "    def get_train_y(self):\n",
    "        return self.train_y\n",
    "\n",
    "    def set_train_y(self, train_y):\n",
    "        self.train_y = train_y\n",
    "\n",
    "    def get_val_X(self):\n",
    "        return self.val_X\n",
    "    \n",
    "    def set_val_X(self, val_X):\n",
    "        self.val_X = val_X\n",
    "\n",
    "    def get_val_y(self):\n",
    "        return self.val_y\n",
    "\n",
    "    def set_val_y(self, val_y):\n",
    "        self.val_y = val_y\n",
    "\n",
    "    def get_test_X(self):\n",
    "        return self.test_X\n",
    "\n",
    "    def set_test_X(self, test_X):\n",
    "        self.test_X = test_X\n",
    "\n",
    "    def get_test_y(self):\n",
    "        return self.test_y\n",
    "\n",
    "    def set_test_y(self, test_y):\n",
    "        self.test_y = test_y\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def get_final_score(self):\n",
    "        return self.final_score\n",
    "\n",
    "    def set_final_score(self, final_score):\n",
    "        self.final_score = final_score\n",
    "\n",
    "    def get_prep_data(self):\n",
    "        return self.prep_data\n",
    "\n",
    "    def set_prep_data(self, prep_data):\n",
    "        self.prep_data = prep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_RAW_PATH = '/Users/metis_sotangkur/Desktop/Kiddi_ds/Data/is_raw_idd.xlsx'\n",
    "IWP_PATH = '/Users/metis_sotangkur/Desktop/Kiddi_ds/Data/iwp_raw_idd.xlsx'\n",
    "IWES_PATH = '/Users/metis_sotangkur/Desktop/Kiddi_ds/Data/iwes_raw_idd.xlsx'\n",
    "CENSUS_PATH = '/Users/metis_sotangkur/Desktop/Kiddi_ds/Data/census_idd.xlsx'\n",
    "kiddi = Kiddi(IS_RAW_PATH, IWP_PATH, IWES_PATH, CENSUS_PATH)\n",
    "kiddi.clean_data()\n",
    "kiddi.gen_population()\n",
    "kiddi.gen_target()\n",
    "kiddi.partition_is_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-4159eabe175f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkiddi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_engineer_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-260-db6cb1ee142f>\u001b[0m in \u001b[0;36mfeature_engineer_ts\u001b[0;34m(self, month)\u001b[0m\n\u001b[1;32m    331\u001b[0m                                 \u001b[0;34m,\u001b[0m \u001b[0mmax_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                                 \u001b[0;31m# , rank_ts(self, ts_df, col_list, col, duration)\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                                 , last_ts(self, ts_df, col)], axis=1)\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kiddi.feature_engineer_ts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiddi.feature_engineer_segment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idd</th>\n",
       "      <th>ft_data_dt</th>\n",
       "      <th>qSodiumVal</th>\n",
       "      <th>qPotassVal</th>\n",
       "      <th>qBicarbVal</th>\n",
       "      <th>qCreatVal</th>\n",
       "      <th>qCaTotalVal</th>\n",
       "      <th>qPhosphVal</th>\n",
       "      <th>qFGF23Val</th>\n",
       "      <th>qMagnesiumVal</th>\n",
       "      <th>...</th>\n",
       "      <th>qWeightVal</th>\n",
       "      <th>qWeightVolVal</th>\n",
       "      <th>qPTBloodTransUnit</th>\n",
       "      <th>qPTBloodTransYN</th>\n",
       "      <th>qIndicateLoc</th>\n",
       "      <th>qFacilityPDVisit</th>\n",
       "      <th>qHomePDVisit</th>\n",
       "      <th>qHomePDVisitCnt</th>\n",
       "      <th>BactInfec</th>\n",
       "      <th>DialAccessRelInfec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>8020013</td>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>8020013</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>8020013</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>8020013</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.33</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>8020013</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>8020013</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>141.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.95</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idd ft_data_dt  qSodiumVal  qPotassVal  qBicarbVal  qCreatVal  \\\n",
       "578   8020013 2016-07-31         NaN         NaN         NaN       6.40   \n",
       "1375  8020013 2016-09-30       128.0         3.0        34.0       7.75   \n",
       "1675  8020013 2016-10-31       133.0         2.9        29.0       9.20   \n",
       "2309  8020013 2016-12-31       132.0         4.1        32.0       7.33   \n",
       "2900  8020013 2017-02-28       131.0         5.9        28.0       8.25   \n",
       "3300  8020013 2017-04-30       141.0         5.4        30.0       8.95   \n",
       "\n",
       "      qCaTotalVal  qPhosphVal  qFGF23Val  qMagnesiumVal  ...  qWeightVal  \\\n",
       "578           NaN         NaN        NaN            NaN  ...         NaN   \n",
       "1375          8.3         NaN        NaN            NaN  ...         NaN   \n",
       "1675          NaN         NaN        NaN            NaN  ...         NaN   \n",
       "2309          8.1         0.9        NaN            NaN  ...         NaN   \n",
       "2900          NaN         NaN        NaN            NaN  ...         NaN   \n",
       "3300          8.0         1.5        NaN            NaN  ...         NaN   \n",
       "\n",
       "      qWeightVolVal  qPTBloodTransUnit  qPTBloodTransYN  qIndicateLoc  \\\n",
       "578             NaN                NaN              NaN           NaN   \n",
       "1375            NaN                NaN              0.0           NaN   \n",
       "1675            NaN                NaN              0.0           NaN   \n",
       "2309            NaN                NaN              0.0           NaN   \n",
       "2900            NaN                NaN              0.0           NaN   \n",
       "3300            NaN                NaN              0.0           NaN   \n",
       "\n",
       "      qFacilityPDVisit  qHomePDVisit  qHomePDVisitCnt  BactInfec  \\\n",
       "578                NaN           NaN              NaN        NaN   \n",
       "1375               1.0           0.0              NaN        1.0   \n",
       "1675               1.0           0.0              NaN        0.0   \n",
       "2309               1.0           0.0              NaN        0.0   \n",
       "2900               1.0           0.0              NaN        0.0   \n",
       "3300               1.0           0.0              NaN        0.0   \n",
       "\n",
       "      DialAccessRelInfec  \n",
       "578                  NaN  \n",
       "1375                 4.0  \n",
       "1675                 NaN  \n",
       "2309                 NaN  \n",
       "2900                 NaN  \n",
       "3300                 NaN  \n",
       "\n",
       "[6 rows x 148 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = kiddi.get_df()\n",
    "k[k['idd'] == 8020013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idd</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>male</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PDVintage</th>\n",
       "      <th>MQexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000001</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.485284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000002</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.214237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8000003</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.206023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8000004</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.746749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8000005</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.204654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>8021065</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>8021066</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>8021067</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627</th>\n",
       "      <td>8021068</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>8021069</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4629 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idd  PatientAge  male  Diabetes  PDVintage  MQexist\n",
       "0     8000001        41.0     0       0.0   7.485284        1\n",
       "1     8000002        65.0     0       0.0   7.214237        0\n",
       "2     8000003        59.0     0       0.0   7.206023        0\n",
       "3     8000004        47.0     0       1.0   5.746749        1\n",
       "4     8000005        91.0     1       0.0   5.204654        1\n",
       "...       ...         ...   ...       ...        ...      ...\n",
       "4624  8021065        65.0     1       0.0   0.046543        1\n",
       "4625  8021066        37.0     0       0.0   0.030116        1\n",
       "4626  8021067        45.0     0       1.0   0.019165        0\n",
       "4627  8021068        69.0     0       0.0   0.000000        1\n",
       "4628  8021069        28.0     0       0.0        NaN        0\n",
       "\n",
       "[4629 rows x 6 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiddi.get_df_cencus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# List of Tuples\n",
    "students = [('jack',    34,     'Sydney',  155),\n",
    "            ('Riti',    31,     'Delhi',   177.5),\n",
    "            ('Aadi',    16,     'Mumbai',  81),\n",
    "            ('Mohit',   31,     'Delhi',   np.NaN),\n",
    "            ('Veena',   np.NaN, 'Delhi',   144),\n",
    "            ('Shaunak', 35,     'Mumbai',  135),\n",
    "            ('Shaun',   35,     'Colombo', 111) ]\n",
    "# Create a DataFrame object\n",
    "df = pd.DataFrame(students,\n",
    "                  columns=['Name', 'Age', 'City', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  189.0\n",
       "1  208.5\n",
       "2   97.0\n",
       "3   31.0\n",
       "4  144.0\n",
       "5  170.0\n",
       "6  146.0"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Age','Score']].sum(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
